{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Description: The people voted for major government reform\n",
      "User Join Date: Joined June 2009\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "def scrape_twitter_profile(username):\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        try:\n",
    "            user_description_div = driver.find_element(By.CSS_SELECTOR, 'div[data-testid=\"UserDescription\"]')\n",
    "            user_description = user_description_div.text\n",
    "        except Exception as e:\n",
    "            user_description = \"No description found\"\n",
    "        \n",
    "        try:\n",
    "            user_join_date_div = driver.find_element(By.CSS_SELECTOR, 'span[data-testid=\"UserJoinDate\"]')\n",
    "\n",
    "            user_join_date = user_join_date_div.text\n",
    "        except Exception as e:\n",
    "            user_join_date = \"No join date found\"\n",
    "        \n",
    "        print(\"User Description:\", user_description)\n",
    "        print(\"User Join Date:\", user_join_date)\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "scrape_twitter_profile('elonmusk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84ddb2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Tweet 1:\n",
      "Text: \n",
      "Comments: 6.1K\n",
      "Retweets: 6.1K\n",
      "---\n",
      "Tweet 2:\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Comments: 176K\n",
      "Retweets: 176K\n",
      "---\n",
      "Tweet 3:\n",
      "Text: No text tweet\n",
      "Comments: 73K\n",
      "Retweets: 73K\n",
      "---\n",
      "Tweet 4:\n",
      "Text: I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
      "Comments: 166K\n",
      "Retweets: 166K\n",
      "---\n",
      "Tweet 5:\n",
      "Text: The future is gonna be so  \n",
      "Comments: 60K\n",
      "Retweets: 60K\n",
      "---\n",
      "Tweet 6:\n",
      "Text: \n",
      "Comments: 6.1K\n",
      "Retweets: 6.1K\n",
      "---\n",
      "Tweet 7:\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Comments: 176K\n",
      "Retweets: 176K\n",
      "---\n",
      "Tweet 8:\n",
      "Text: No text tweet\n",
      "Comments: 73K\n",
      "Retweets: 73K\n",
      "---\n",
      "Tweet 9:\n",
      "Text: I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
      "Comments: 166K\n",
      "Retweets: 166K\n",
      "---\n",
      "Tweet 10:\n",
      "Text: The future is gonna be so  \n",
      "Comments: 60K\n",
      "Retweets: 60K\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "def scrape_twitter_tweets(username, tweet_count):\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        tweets_data = []\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while len(tweets_data) < tweet_count and scroll_attempts < 10:\n",
    "            tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "            print(scroll_attempts)\n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    try:\n",
    "                        tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').text\n",
    "                    except Exception:\n",
    "                        tweet_text = 'No text tweet'\n",
    "                    \n",
    "                    try:\n",
    "                        comments_span = tweet.find_element(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                        comments = comments_span.text\n",
    "                    except Exception:\n",
    "                        comments = \"No comments found\"\n",
    "                    \n",
    "                    try:\n",
    "                        retweet_button = tweet.find_element(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                        retweet_text = retweet_button.text\n",
    "                    except Exception:\n",
    "                        retweet_text = \"No retweets found\"\n",
    "                    \n",
    "                    tweets_data.append({\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'comments': comments,\n",
    "                        'retweets': retweet_text\n",
    "                    })\n",
    "                    \n",
    "                    if len(tweets_data) >= tweet_count:\n",
    "                        break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting tweet:\", e)\n",
    "                    continue\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(2) \n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        for i, tweet in enumerate(tweets_data[:tweet_count]):\n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(\"Text:\", tweet['tweet_text'])\n",
    "            print(\"Comments:\", tweet['comments'])\n",
    "            print(\"Retweets:\", tweet['retweets'])\n",
    "            print(\"---\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "scrape_twitter_tweets('elonmusk', tweet_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e4f03c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=130.0.6723.117)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6CD7238A5+3004357]\n\t(No symbol) [0x00007FF6CD3B9970]\n\t(No symbol) [0x00007FF6CD26582A]\n\t(No symbol) [0x00007FF6CD23FA75]\n\t(No symbol) [0x00007FF6CD2E2C77]\n\t(No symbol) [0x00007FF6CD2FB351]\n\t(No symbol) [0x00007FF6CD2DB983]\n\t(No symbol) [0x00007FF6CD2A7628]\n\t(No symbol) [0x00007FF6CD2A8791]\n\tGetHandleVerifier [0x00007FF6CD74A00D+3161901]\n\tGetHandleVerifier [0x00007FF6CD79E060+3506048]\n\tGetHandleVerifier [0x00007FF6CD79400D+3465005]\n\tGetHandleVerifier [0x00007FF6CD510EEB+830987]\n\t(No symbol) [0x00007FF6CD3C467F]\n\t(No symbol) [0x00007FF6CD3C09D4]\n\t(No symbol) [0x00007FF6CD3C0B6D]\n\t(No symbol) [0x00007FF6CD3B0149]\n\tBaseThreadInitThunk [0x00007FFE0C17259D+29]\n\tRtlUserThreadStart [0x00007FFE0D62AF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m         driver\u001b[38;5;241m.\u001b[39mquit()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Run the function for a specific user\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[43mscrape_twitter_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melonmusk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m, in \u001b[0;36mscrape_twitter_tweets\u001b[1;34m(username, tweet_count)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://twitter.com/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musername\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle[data-testid=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     tweets_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     17\u001b[0m     scroll_attempts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\project\\TwitterCrawler\\.venv\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:96\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m     98\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\project\\TwitterCrawler\\.venv\\Lib\\site-packages\\selenium\\webdriver\\support\\expected_conditions.py:84\u001b[0m, in \u001b[0;36mpresence_of_element_located.<locals>._predicate\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predicate\u001b[39m(driver: WebDriverOrWebElement):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlocator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\project\\TwitterCrawler\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:766\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchElementException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot locate relative element with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mby\u001b[38;5;241m.\u001b[39mroot\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elements[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\project\\TwitterCrawler\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:380\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    378\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\project\\TwitterCrawler\\.venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=130.0.6723.117)\nStacktrace:\n\tGetHandleVerifier [0x00007FF6CD7238A5+3004357]\n\t(No symbol) [0x00007FF6CD3B9970]\n\t(No symbol) [0x00007FF6CD26582A]\n\t(No symbol) [0x00007FF6CD23FA75]\n\t(No symbol) [0x00007FF6CD2E2C77]\n\t(No symbol) [0x00007FF6CD2FB351]\n\t(No symbol) [0x00007FF6CD2DB983]\n\t(No symbol) [0x00007FF6CD2A7628]\n\t(No symbol) [0x00007FF6CD2A8791]\n\tGetHandleVerifier [0x00007FF6CD74A00D+3161901]\n\tGetHandleVerifier [0x00007FF6CD79E060+3506048]\n\tGetHandleVerifier [0x00007FF6CD79400D+3465005]\n\tGetHandleVerifier [0x00007FF6CD510EEB+830987]\n\t(No symbol) [0x00007FF6CD3C467F]\n\t(No symbol) [0x00007FF6CD3C09D4]\n\t(No symbol) [0x00007FF6CD3C0B6D]\n\t(No symbol) [0x00007FF6CD3B0149]\n\tBaseThreadInitThunk [0x00007FFE0C17259D+29]\n\tRtlUserThreadStart [0x00007FFE0D62AF38+40]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "''''''\n",
    "\n",
    "def scrape_twitter_tweets(username, tweet_count):\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')))\n",
    "        \n",
    "        tweets_data = []\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while len(tweets_data) < tweet_count and scroll_attempts < 10:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')))\n",
    "            tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    try:\n",
    "                        tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').text\n",
    "                    except Exception:\n",
    "                        tweet_text = 'No text tweet'\n",
    "                    \n",
    "                    try:\n",
    "                        spans = tweet.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                        replies = spans[0].text if len(spans) > 0 else \"No replies\"\n",
    "                        reposts = spans[1].text if len(spans) > 1 else \"No reposts\"\n",
    "                        likes = spans[2].text if len(spans) > 2 else \"No likes\"\n",
    "                        views = spans[3].text if len(spans) > 3 else \"No views\"\n",
    "                    except Exception:\n",
    "                        replies, reposts, likes, views = \"No replies\", \"No reposts\", \"No likes\", \"No views\"\n",
    "                    \n",
    "                    tweets_data.append({\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'replies': replies,\n",
    "                        'reposts': reposts,\n",
    "                        'likes': likes,\n",
    "                        'views': views\n",
    "                    })\n",
    "                    \n",
    "                    if len(tweets_data) >= tweet_count:\n",
    "                        break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting tweet:\", e)\n",
    "                    continue\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(2) \n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        for i, tweet in enumerate(tweets_data[:tweet_count]):\n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(\"Text:\", tweet['tweet_text'])\n",
    "            print(\"Replies:\", tweet['replies'])\n",
    "            print(\"Reposts:\", tweet['reposts'])\n",
    "            print(\"Likes:\", tweet['likes'])\n",
    "            print(\"Views:\", tweet['views'])\n",
    "            print(\"---\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Run the function for a specific user\n",
    "scrape_twitter_tweets('elonmusk', tweet_count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77d755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll attempt: 0, Found tweets: 2\n",
      "Scroll attempt: 1, Found tweets: 7\n",
      "Scroll attempt: 2, Found tweets: 10\n",
      "Tweet 1:\n",
      "Text: \n",
      "Replies: 6.3K\n",
      "Retweets: 10K\n",
      "Likes: 117K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n",
      "Tweet 2:\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Replies: 176K\n",
      "Retweets: 784K\n",
      "Likes: 4.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 3:\n",
      "Text: \n",
      "Replies: 6.3K\n",
      "Retweets: 10K\n",
      "Likes: 117K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n",
      "Tweet 4:\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Replies: 176K\n",
      "Retweets: 784K\n",
      "Likes: 4.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 5:\n",
      "Text: No text tweet\n",
      "Replies: 73K\n",
      "Retweets: 458K\n",
      "Likes: 3.4M\n",
      "Views: 242M\n",
      "---\n",
      "Tweet 6:\n",
      "Text: I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
      "Replies: 166K\n",
      "Retweets: 403K\n",
      "Likes: 2.9M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 7:\n",
      "Text: The future is gonna be so  \n",
      "Replies: 60K\n",
      "Retweets: 235K\n",
      "Likes: 2.7M\n",
      "Views: 157M\n",
      "---\n",
      "Tweet 8:\n",
      "Text: Let’s make Twitter maximum fun!\n",
      "Replies: 106K\n",
      "Retweets: 208K\n",
      "Likes: 2.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 9:\n",
      "Text:  Yesss!!! \n",
      "Replies: 137K\n",
      "Retweets: 374K\n",
      "Likes: 2.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 10:\n",
      "Text: \n",
      "Replies: 6.3K\n",
      "Retweets: 10K\n",
      "Likes: 117K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"waite for the page be uploaded and get the replyed or queted tweet and add randomness\"\"\"\n",
    "\n",
    "def scrape_twitter_tweets(username, tweet_count):\n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]'))\n",
    "        )\n",
    "        \n",
    "        tweets_data = []\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while len(tweets_data) < tweet_count and scroll_attempts < 10:\n",
    "            tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "            print(f\"Scroll attempt: {scroll_attempts}, Found tweets: {len(tweets)}\")\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    try:\n",
    "                        tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').text\n",
    "                    except Exception:\n",
    "                        tweet_text = 'No text tweet'\n",
    "                    \n",
    "                    counts = tweet.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                    reply_count = counts[0].text if len(counts) > 0 else 'No replies'\n",
    "                    retweet_count = counts[1].text if len(counts) > 1 else 'No retweets'\n",
    "                    like_count = counts[2].text if len(counts) > 2 else 'No likes'\n",
    "                    view_count = counts[3].text if len(counts) > 3 else 'No views'\n",
    "                    \n",
    "                    try:\n",
    "                        usernames = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"User-Name\"]')\n",
    "                        if len(usernames) > 1:  # A second username indicates a reply or quote\n",
    "                            replied_username = usernames[1].text  # Second username\n",
    "                            try:\n",
    "                                replied_text = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')[1].text\n",
    "                            except Exception:\n",
    "                                replied_text = \"No replied tweet text found\"\n",
    "                        else:\n",
    "                            replied_username = None\n",
    "                            replied_text = None\n",
    "                    except Exception:\n",
    "                        replied_username = None\n",
    "                        replied_text = None\n",
    "                    \n",
    "                    tweet_data = {\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'replies': reply_count,\n",
    "                        'retweets': retweet_count,\n",
    "                        'likes': like_count,\n",
    "                        'views': view_count\n",
    "                    }\n",
    "                    \n",
    "                    if replied_username and replied_text:\n",
    "                        tweet_data['replied_to'] = {\n",
    "                            'username': replied_username,\n",
    "                            'text': replied_text\n",
    "                        }\n",
    "                    \n",
    "                    tweets_data.append(tweet_data)\n",
    "                    \n",
    "\n",
    "                    if len(tweets_data) >= tweet_count:\n",
    "                        break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting tweet:\", e)\n",
    "                    continue\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(random.uniform(2, 5))  # Random delay between 2 to 5 seconds\n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        for i, tweet in enumerate(tweets_data[:tweet_count]):\n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(\"Text:\", tweet['tweet_text'])\n",
    "            print(\"Replies:\", tweet['replies'])\n",
    "            print(\"Retweets:\", tweet['retweets'])\n",
    "            print(\"Likes:\", tweet['likes'])\n",
    "            print(\"Views:\", tweet['views'])\n",
    "            if 'replied_to' in tweet:\n",
    "                print(\"Replied to:\")\n",
    "                print(\"  Username:\", tweet['replied_to']['username'])\n",
    "                print(\"  Text:\", tweet['replied_to']['text'])\n",
    "            print(\"---\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage\n",
    "scrape_twitter_tweets('elonmusk', tweet_count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1909124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll attempt: 0, Found tweets: 5\n",
      "Image saved to downloaded_images\\elonmusk_tweet_1_1.jpg\n",
      "Image elonmusk_tweet_1_1.jpg saved as quoted tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_3_1.jpg\n",
      "Image elonmusk_tweet_3_1.jpg saved as original tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_5_1.jpg\n",
      "Image elonmusk_tweet_5_1.jpg saved as original tweet\n",
      "Scroll attempt: 1, Found tweets: 7\n",
      "Image saved to downloaded_images\\elonmusk_tweet_6_1.jpg\n",
      "Image elonmusk_tweet_6_1.jpg saved as quoted tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_8_1.jpg\n",
      "Image elonmusk_tweet_8_1.jpg saved as original tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_10_1.jpg\n",
      "Image elonmusk_tweet_10_1.jpg saved as original tweet\n",
      "Tweet 1:\n",
      "Text: \n",
      "Replies: 6.1K\n",
      "Retweets: 10K\n",
      "Likes: 116K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n",
      "Tweet 2:\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Replies: 176K\n",
      "Retweets: 784K\n",
      "Likes: 4.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 3:\n",
      "Text: No text tweet\n",
      "Replies: 73K\n",
      "Retweets: 458K\n",
      "Likes: 3.4M\n",
      "Views: 242M\n",
      "---\n",
      "Tweet 4:\n",
      "Text: I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
      "Replies: 166K\n",
      "Retweets: 403K\n",
      "Likes: 2.9M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 5:\n",
      "Text: The future is gonna be so  \n",
      "Replies: 60K\n",
      "Retweets: 235K\n",
      "Likes: 2.7M\n",
      "Views: 157M\n",
      "---\n",
      "Tweet 6:\n",
      "Text: \n",
      "Replies: 6.1K\n",
      "Retweets: 10K\n",
      "Likes: 116K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n",
      "Tweet 7:\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Replies: 176K\n",
      "Retweets: 784K\n",
      "Likes: 4.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 8:\n",
      "Text: No text tweet\n",
      "Replies: 73K\n",
      "Retweets: 458K\n",
      "Likes: 3.4M\n",
      "Views: 242M\n",
      "---\n",
      "Tweet 9:\n",
      "Text: I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
      "Replies: 166K\n",
      "Retweets: 403K\n",
      "Likes: 2.9M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 10:\n",
      "Text: The future is gonna be so  \n",
      "Replies: 60K\n",
      "Retweets: 235K\n",
      "Likes: 2.7M\n",
      "Views: 157M\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Handle the images.\n",
    "\"\"\"\n",
    "\n",
    "def download_image(img_url, save_path):\n",
    "    try:\n",
    "        response = requests.get(img_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Image saved to {save_path}\")\n",
    "        else:\n",
    "            print(\"Failed to download image.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "def scrape_twitter_tweets(username, tweet_count, download_folder=\"downloaded_images\"):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]'))\n",
    "        )\n",
    "        \n",
    "        tweets_data = []\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while len(tweets_data) < tweet_count and scroll_attempts < 10:\n",
    "            tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "            print(f\"Scroll attempt: {scroll_attempts}, Found tweets: {len(tweets)}\")\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    try:\n",
    "                        tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').text\n",
    "                    except Exception:\n",
    "                        tweet_text = 'No text tweet'\n",
    "                    \n",
    "                    counts = tweet.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                    reply_count = counts[0].text if len(counts) > 0 else 'No replies'\n",
    "                    retweet_count = counts[1].text if len(counts) > 1 else 'No retweets'\n",
    "                    like_count = counts[2].text if len(counts) > 2 else 'No likes'\n",
    "                    view_count = counts[3].text if len(counts) > 3 else 'No views'\n",
    "                    \n",
    "                    # Check for a second 'data-testid=\"User-Name\"' (indicates a reply or quote)\n",
    "                    try:\n",
    "                        usernames = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"User-Name\"]')\n",
    "                        if len(usernames) > 1:  # A second username indicates a reply or quote\n",
    "                            replied_username = usernames[1].text  # Second username\n",
    "                            try:\n",
    "                                replied_text = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')[1].text\n",
    "                            except Exception:\n",
    "                                replied_text = \"No replied tweet text found\"\n",
    "                        else:\n",
    "                            replied_username = None\n",
    "                            replied_text = None\n",
    "                    except Exception:\n",
    "                        replied_username = None\n",
    "                        replied_text = None\n",
    "                    \n",
    "                    tweet_photos = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetPhoto\"]')\n",
    "                    if tweet_photos:\n",
    "                        for idx, photo in enumerate(tweet_photos):\n",
    "                            img_tag = photo.find_element(By.TAG_NAME, 'img')\n",
    "                            img_url = img_tag.get_attribute('src')\n",
    "                            if img_url:\n",
    "                                if len(tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')) > 1:\n",
    "                                    tweet_type = \"quoted tweet\"\n",
    "                                else:\n",
    "                                    tweet_type = \"original tweet\"\n",
    "                                    \n",
    "                                img_filename = f\"{username}_tweet_{len(tweets_data)+1}_{idx+1}.jpg\"\n",
    "                                save_path = os.path.join(download_folder, img_filename)\n",
    "                                download_image(img_url, save_path)\n",
    "                                print(f\"Image {img_filename} saved as {tweet_type}\")\n",
    "\n",
    "                    tweet_data = {\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'replies': reply_count,\n",
    "                        'retweets': retweet_count,\n",
    "                        'likes': like_count,\n",
    "                        'views': view_count\n",
    "                    }\n",
    "                    \n",
    "                    if replied_username and replied_text:\n",
    "                        tweet_data['replied_to'] = {\n",
    "                            'username': replied_username,\n",
    "                            'text': replied_text\n",
    "                        }\n",
    "                    \n",
    "                    tweets_data.append(tweet_data)\n",
    "                    \n",
    "                    if len(tweets_data) >= tweet_count:\n",
    "                        break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting tweet:\", e)\n",
    "                    continue\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(random.uniform(2, 5)) \n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        for i, tweet in enumerate(tweets_data[:tweet_count]):\n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(\"Text:\", tweet['tweet_text'])\n",
    "            print(\"Replies:\", tweet['replies'])\n",
    "            print(\"Retweets:\", tweet['retweets'])\n",
    "            print(\"Likes:\", tweet['likes'])\n",
    "            print(\"Views:\", tweet['views'])\n",
    "            if 'replied_to' in tweet:\n",
    "                print(\"Replied to:\")\n",
    "                print(\"  Username:\", tweet['replied_to']['username'])\n",
    "                print(\"  Text:\", tweet['replied_to']['text'])\n",
    "            print(\"---\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "scrape_twitter_tweets('elonmusk', tweet_count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785fdc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll attempt: 0, Found tweets: 2\n",
      "Image saved to downloaded_images\\elonmusk_tweet_1_1.jpg\n",
      "Image elonmusk_tweet_1_1.jpg saved as quoted tweet\n",
      "Scroll attempt: 1, Found tweets: 7\n",
      "Image saved to downloaded_images\\elonmusk_tweet_3_1.jpg\n",
      "Image elonmusk_tweet_3_1.jpg saved as quoted tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_5_1.jpg\n",
      "Image elonmusk_tweet_5_1.jpg saved as original tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_7_1.jpg\n",
      "Image elonmusk_tweet_7_1.jpg saved as original tweet\n",
      "Image saved to downloaded_images\\elonmusk_tweet_9_1.jpg\n",
      "Image elonmusk_tweet_9_1.jpg saved as original tweet\n",
      "Scroll attempt: 2, Found tweets: 10\n",
      "Image saved to downloaded_images\\elonmusk_tweet_10_1.jpg\n",
      "Image elonmusk_tweet_10_1.jpg saved as quoted tweet\n",
      "Tweet 1:\n",
      "Tweet ID: No tweet ID\n",
      "Text: \n",
      "Replies: 6.1K\n",
      "Retweets: 10K\n",
      "Likes: 116K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n",
      "Tweet 2:\n",
      "Tweet ID: No tweet ID\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Replies: 176K\n",
      "Retweets: 784K\n",
      "Likes: 4.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 3:\n",
      "Tweet ID: No tweet ID\n",
      "Text: \n",
      "Replies: 6.1K\n",
      "Retweets: 10K\n",
      "Likes: 116K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n",
      "Tweet 4:\n",
      "Tweet ID: No tweet ID\n",
      "Text: Next I’m buying Coca-Cola to put the cocaine back in\n",
      "Replies: 176K\n",
      "Retweets: 784K\n",
      "Likes: 4.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 5:\n",
      "Tweet ID: No tweet ID\n",
      "Text: No text tweet\n",
      "Replies: 73K\n",
      "Retweets: 458K\n",
      "Likes: 3.4M\n",
      "Views: 242M\n",
      "---\n",
      "Tweet 6:\n",
      "Tweet ID: No tweet ID\n",
      "Text: I hope that even my worst critics remain on Twitter, because that is what free speech means\n",
      "Replies: 166K\n",
      "Retweets: 403K\n",
      "Likes: 2.9M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 7:\n",
      "Tweet ID: No tweet ID\n",
      "Text: The future is gonna be so  \n",
      "Replies: 60K\n",
      "Retweets: 235K\n",
      "Likes: 2.7M\n",
      "Views: 157M\n",
      "---\n",
      "Tweet 8:\n",
      "Tweet ID: No tweet ID\n",
      "Text: Let’s make Twitter maximum fun!\n",
      "Replies: 106K\n",
      "Retweets: 208K\n",
      "Likes: 2.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 9:\n",
      "Tweet ID: No tweet ID\n",
      "Text:  Yesss!!! \n",
      "Replies: 137K\n",
      "Retweets: 374K\n",
      "Likes: 2.4M\n",
      "Views: No views\n",
      "---\n",
      "Tweet 10:\n",
      "Tweet ID: No tweet ID\n",
      "Text: \n",
      "Replies: 6.1K\n",
      "Retweets: 10K\n",
      "Likes: 116K\n",
      "Views: 33M\n",
      "Replied to:\n",
      "  Username: Internal Tech Emails\n",
      "@TechEmails\n",
      "·\n",
      "Nov 15\n",
      "  Text: Elon Musk emails OpenAI cofounders\n",
      "\n",
      "September 20, 2017\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Handle the images.\n",
    "\"\"\"\n",
    "\n",
    "def download_image(img_url, save_path):\n",
    "    try:\n",
    "        response = requests.get(img_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Image saved to {save_path}\")\n",
    "        else:\n",
    "            print(\"Failed to download image.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "def scrape_twitter_tweets(username, tweet_count, download_folder=\"downloaded_images\"):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]'))\n",
    "        )\n",
    "        \n",
    "        tweets_data = []\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while len(tweets_data) < tweet_count and scroll_attempts < 10:\n",
    "            tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "            print(f\"Scroll attempt: {scroll_attempts}, Found tweets: {len(tweets)}\")\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    try:\n",
    "                        tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').text\n",
    "                    except Exception:\n",
    "                        tweet_text = 'No text tweet'\n",
    "                    \n",
    "                    counts = tweet.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                    reply_count = counts[0].text if len(counts) > 0 else 'No replies'\n",
    "                    retweet_count = counts[1].text if len(counts) > 1 else 'No retweets'\n",
    "                    like_count = counts[2].text if len(counts) > 2 else 'No likes'\n",
    "                    view_count = counts[3].text if len(counts) > 3 else 'No views'\n",
    "                    \n",
    "                    \n",
    "                    tweet_url = tweet.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                    tweet_id = tweet_url.split('/status/')[1] if '/status/' in tweet_url else 'No tweet ID'\n",
    "\n",
    "                    try:\n",
    "                        usernames = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"User-Name\"]')\n",
    "                        if len(usernames) > 1:  \n",
    "                            replied_username = usernames[1].text  \n",
    "                            try:\n",
    "                                replied_text = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')[1].text\n",
    "                            except Exception:\n",
    "                                replied_text = \"No replied tweet text found\"\n",
    "                        else:\n",
    "                            replied_username = None\n",
    "                            replied_text = None\n",
    "                    except Exception:\n",
    "                        replied_username = None\n",
    "                        replied_text = None\n",
    "                    \n",
    "                    tweet_photos = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetPhoto\"]')\n",
    "                    if tweet_photos:\n",
    "                        for idx, photo in enumerate(tweet_photos):\n",
    "                            img_tag = photo.find_element(By.TAG_NAME, 'img')\n",
    "                            img_url = img_tag.get_attribute('src')\n",
    "                            if img_url:\n",
    "                                if len(tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')) > 1:\n",
    "                                    tweet_type = \"quoted tweet\"\n",
    "                                else:\n",
    "                                    tweet_type = \"original tweet\"\n",
    "                                    \n",
    "                                img_filename = f\"{username}_tweet_{len(tweets_data)+1}_{idx+1}.jpg\"\n",
    "                                save_path = os.path.join(download_folder, img_filename)\n",
    "                                download_image(img_url, save_path)\n",
    "                                print(f\"Image {img_filename} saved as {tweet_type}\")\n",
    "\n",
    "                    tweet_data = {\n",
    "                        'tweet_id': tweet_id,\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'replies': reply_count,\n",
    "                        'retweets': retweet_count,\n",
    "                        'likes': like_count,\n",
    "                        'views': view_count\n",
    "                    }\n",
    "                    \n",
    "                    if replied_username and replied_text:\n",
    "                        tweet_data['replied_to'] = {\n",
    "                            'username': replied_username,\n",
    "                            'text': replied_text\n",
    "                        }\n",
    "                    \n",
    "                    tweets_data.append(tweet_data)\n",
    "                    \n",
    "                    if len(tweets_data) >= tweet_count:\n",
    "                        break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting tweet:\", e)\n",
    "                    continue\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(random.uniform(2, 5)) \n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        for i, tweet in enumerate(tweets_data[:tweet_count]):\n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(\"Tweet ID:\", tweet['tweet_id'])\n",
    "            print(\"Text:\", tweet['tweet_text'])\n",
    "            print(\"Replies:\", tweet['replies'])\n",
    "            print(\"Retweets:\", tweet['retweets'])\n",
    "            print(\"Likes:\", tweet['likes'])\n",
    "            print(\"Views:\", tweet['views'])\n",
    "            if 'replied_to' in tweet:\n",
    "                print(\"Replied to:\")\n",
    "                print(\"  Username:\", tweet['replied_to']['username'])\n",
    "                print(\"  Text:\", tweet['replied_to']['text'])\n",
    "            print(\"---\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "scrape_twitter_tweets('elonmusk', tweet_count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e3f3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "add Time and handle the tweet id\n",
    "\"\"\"\n",
    "\n",
    "def download_image(img_url, save_path):\n",
    "    try:\n",
    "        response = requests.get(img_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(save_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Image saved to {save_path}\")\n",
    "        else:\n",
    "            print(\"Failed to download image.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {e}\")\n",
    "\n",
    "def is_valid_tweet_url(url):\n",
    "    \"\"\"Check if the URL is a valid tweet URL of the form username/status/tweet_id.\"\"\"\n",
    "    return '/status/' in url and not any(ext in url for ext in ['/photo', '/analysis', '/video', '/moment/'])\n",
    "\n",
    "def scrape_twitter_tweets(username, tweet_count, download_folder=\"downloaded_images\", image_downloading=False):\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    driver = webdriver.Chrome()\n",
    "    \n",
    "    try:\n",
    "        driver.get(f'https://twitter.com/{username}')\n",
    "        \n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]'))\n",
    "        )\n",
    "        \n",
    "        tweets_data = []\n",
    "        scroll_attempts = 0\n",
    "        \n",
    "        while len(tweets_data) < tweet_count and scroll_attempts < 10:\n",
    "            tweets = driver.find_elements(By.CSS_SELECTOR, 'article[data-testid=\"tweet\"]')\n",
    "            print(f\"Scroll attempt: {scroll_attempts}, Found tweets: {len(tweets)}\")\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "\n",
    "                    tweet_url = None\n",
    "                    links = tweet.find_elements(By.TAG_NAME, 'a')\n",
    "                    for link in links:\n",
    "                        url = link.get_attribute('href')\n",
    "                        if is_valid_tweet_url(url):\n",
    "                            tweet_url = url\n",
    "                            break  \n",
    "                    \n",
    "                    tweet_id = tweet_url.split('/status/')[1].split('/')[0] if tweet_url else 'No tweet ID'\n",
    "                    \n",
    "                    if any(t['tweet_id'] == tweet_id for t in tweets_data):\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        tweet_text = tweet.find_element(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]').text\n",
    "                    except Exception:\n",
    "                        tweet_text = 'No text tweet'\n",
    "                    tweet_time = tweet.find_element(By.TAG_NAME, 'time').text\n",
    "                    counts = tweet.find_elements(By.CSS_SELECTOR, 'span[data-testid=\"app-text-transition-container\"]')\n",
    "                    reply_count = counts[0].text if len(counts) > 0 else 'No replies'\n",
    "                    retweet_count = counts[1].text if len(counts) > 1 else 'No retweets'\n",
    "                    like_count = counts[2].text if len(counts) > 2 else 'No likes'\n",
    "                    view_count = counts[3].text if len(counts) > 3 else 'No views'\n",
    "                    \n",
    " \n",
    "\n",
    "                    try:\n",
    "                        usernames = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"User-Name\"]')\n",
    "                        if len(usernames) > 1:  \n",
    "                            replied_username = usernames[1].text\n",
    "                            try:\n",
    "                                replied_text = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')[1].text\n",
    "                            except Exception:\n",
    "                                replied_text = \"No replied tweet text found\"\n",
    "                            \n",
    "                            replied_time = tweet.find_elements(By.TAG_NAME, 'time')[1].text\n",
    "\n",
    "                            links = tweet.find_elements(By.TAG_NAME, 'a')[1] \n",
    "                            for link in links:\n",
    "                                url = link.get_attribute('href')\n",
    "                                if is_valid_tweet_url(url):\n",
    "                                    if url.split('/status/')[0] == replied_username:\n",
    "                                        replied_tweet_url = url\n",
    "                                        break  \n",
    "                                    reply_tweet_id = tweet_url.split('/status/')[1].split('/')[0] if tweet_url else 'No tweet ID'\n",
    "\n",
    "                        else:\n",
    "                            replied_username = None\n",
    "                            replied_text = None\n",
    "                            reply_tweet_id = None\n",
    "                    except Exception:\n",
    "                        replied_username = None\n",
    "                        replied_text = None\n",
    "                        reply_tweet_id = None\n",
    "                    \n",
    "                    tweet_photos = tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetPhoto\"]')\n",
    "                    if tweet_photos and image_downloading:\n",
    "                        for idx, photo in enumerate(tweet_photos):\n",
    "                            img_tag = photo.find_element(By.TAG_NAME, 'img')\n",
    "                            img_url = img_tag.get_attribute('src')\n",
    "                            if img_url:\n",
    "                                if len(tweet.find_elements(By.CSS_SELECTOR, 'div[data-testid=\"tweetText\"]')) > 1:\n",
    "                                    tweet_type = \"quoted_tweet\"\n",
    "                                else:\n",
    "                                    tweet_type = \"original_tweet\"\n",
    "                                    \n",
    "                                img_filename = f\"{username}_tweet_{tweet_id}_{tweet_type}.jpg\"\n",
    "                                save_path = os.path.join(download_folder, img_filename)\n",
    "                                download_image(img_url, save_path)\n",
    "                                print(f\"Image {img_filename} saved as {tweet_type}\")\n",
    "\n",
    "                    tweet_data = {\n",
    "                        'tweet_id': tweet_id,\n",
    "                        'time': tweet_time,\n",
    "                        'tweet_url': tweet_url,\n",
    "                        'tweet_text': tweet_text,\n",
    "                        'replies': reply_count,\n",
    "                        'retweets': retweet_count,\n",
    "                        'likes': like_count,\n",
    "                        'views': view_count\n",
    "                    }\n",
    "                    \n",
    "                    if replied_username and replied_text:\n",
    "                        tweet_data['replied_to'] = {\n",
    "                            'username': replied_username,\n",
    "                            'text': replied_text,\n",
    "                            'time': replied_time,\n",
    "                            'reply_tweet_id': reply_tweet_id,\n",
    "                            'reply_twee_url': replied_tweet_url,\n",
    "                        }\n",
    "                    \n",
    "                    tweets_data.append(tweet_data)\n",
    "                    \n",
    "                    if len(tweets_data) >= tweet_count:\n",
    "                        break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Error extracting tweet:\", e)\n",
    "                    continue\n",
    "            \n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(random.uniform(2, 5)) \n",
    "            scroll_attempts += 1\n",
    "        \n",
    "        for i, tweet in enumerate(tweets_data[:tweet_count]):\n",
    "            print(f\"Tweet {i+1}:\")\n",
    "            print(\"Tweet ID:\", tweet['tweet_id'])\n",
    "            print(\"Tweet URl:\", tweet['tweet_url'])\n",
    "            print(\"Tweet Time:\", tweet[\"time\"])\n",
    "            print(\"Text:\", tweet['tweet_text'])\n",
    "            print(\"Replies:\", tweet['replies'])\n",
    "            print(\"Retweets:\", tweet['retweets'])\n",
    "            print(\"Likes:\", tweet['likes'])\n",
    "            print(\"Views:\", tweet['views'])\n",
    "            if 'replied_to' in tweet:\n",
    "                print(\"Replied to:\")\n",
    "                print(\"  Reply Tweet ID:\", tweet['replied_to']['reply_tweet_id'])\n",
    "                print(\"  Reply Tweet Url:\", tweet['replied_to']['reply_twee_url'])\n",
    "                print(\"  Username:\", tweet['replied_to']['username'])\n",
    "                print(\"  Time:\", tweet['replied_to']['time'])\n",
    "                print(\"  Text:\", tweet['replied_to']['text'])\n",
    "\n",
    "            print(\"---\")\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "# scrape_twitter_tweets('elonmusk', tweet_count=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b2fb87c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF6CD7238A5+3004357]\n\t(No symbol) [0x00007FF6CD3B9970]\n\t(No symbol) [0x00007FF6CD26582A]\n\t(No symbol) [0x00007FF6CD2B5B8E]\n\t(No symbol) [0x00007FF6CD2B5E7C]\n\t(No symbol) [0x00007FF6CD2FEC27]\n\t(No symbol) [0x00007FF6CD2DBC1F]\n\t(No symbol) [0x00007FF6CD2FBA4C]\n\t(No symbol) [0x00007FF6CD2DB983]\n\t(No symbol) [0x00007FF6CD2A7628]\n\t(No symbol) [0x00007FF6CD2A8791]\n\tGetHandleVerifier [0x00007FF6CD74A00D+3161901]\n\tGetHandleVerifier [0x00007FF6CD79E060+3506048]\n\tGetHandleVerifier [0x00007FF6CD79400D+3465005]\n\tGetHandleVerifier [0x00007FF6CD510EEB+830987]\n\t(No symbol) [0x00007FF6CD3C467F]\n\t(No symbol) [0x00007FF6CD3C09D4]\n\t(No symbol) [0x00007FF6CD3C0B6D]\n\t(No symbol) [0x00007FF6CD3B0149]\n\tBaseThreadInitThunk [0x00007FFE0C17259D+29]\n\tRtlUserThreadStart [0x00007FFE0D62AF38+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mscrape_twitter_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melonmusk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_downloading\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 40\u001b[0m, in \u001b[0;36mscrape_twitter_tweets\u001b[1;34m(username, tweet_count, download_folder, image_downloading)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://twitter.com/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00musername\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43marticle[data-testid=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtweet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     tweets_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m     scroll_attempts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Desktop\\project\\TwitterCrawler\\.venv\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    104\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll)\n\u001b[1;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[1;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n\tGetHandleVerifier [0x00007FF6CD7238A5+3004357]\n\t(No symbol) [0x00007FF6CD3B9970]\n\t(No symbol) [0x00007FF6CD26582A]\n\t(No symbol) [0x00007FF6CD2B5B8E]\n\t(No symbol) [0x00007FF6CD2B5E7C]\n\t(No symbol) [0x00007FF6CD2FEC27]\n\t(No symbol) [0x00007FF6CD2DBC1F]\n\t(No symbol) [0x00007FF6CD2FBA4C]\n\t(No symbol) [0x00007FF6CD2DB983]\n\t(No symbol) [0x00007FF6CD2A7628]\n\t(No symbol) [0x00007FF6CD2A8791]\n\tGetHandleVerifier [0x00007FF6CD74A00D+3161901]\n\tGetHandleVerifier [0x00007FF6CD79E060+3506048]\n\tGetHandleVerifier [0x00007FF6CD79400D+3465005]\n\tGetHandleVerifier [0x00007FF6CD510EEB+830987]\n\t(No symbol) [0x00007FF6CD3C467F]\n\t(No symbol) [0x00007FF6CD3C09D4]\n\t(No symbol) [0x00007FF6CD3C0B6D]\n\t(No symbol) [0x00007FF6CD3B0149]\n\tBaseThreadInitThunk [0x00007FFE0C17259D+29]\n\tRtlUserThreadStart [0x00007FFE0D62AF38+40]\n"
     ]
    }
   ],
   "source": [
    "scrape_twitter_tweets('elonmusk', tweet_count=20, image_downloading=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff583d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll attempt: 0, Found tweets: 2\n",
      "Scroll attempt: 1, Found tweets: 14\n",
      "Scroll attempt: 2, Found tweets: 18\n",
      "Scroll attempt: 3, Found tweets: 19\n",
      "Scroll attempt: 4, Found tweets: 14\n",
      "Scroll attempt: 5, Found tweets: 10\n",
      "Scroll attempt: 6, Found tweets: 10\n",
      "Scroll attempt: 7, Found tweets: 11\n",
      "Scroll attempt: 8, Found tweets: 10\n",
      "Scroll attempt: 9, Found tweets: 10\n",
      "Tweet 1:\n",
      "Tweet ID: 1212986012814712832\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1212986012814712832\n",
      "Tweet Time: Jan 3, 2020\n",
      "Text: In the Name of God, the Beneficent, the Merciful\n",
      "Replies: 23K\n",
      "Retweets: 14K\n",
      "Likes: 74K\n",
      "Views: No views\n",
      "---\n",
      "Tweet 2:\n",
      "Tweet ID: 1854960835757756505\n",
      "Tweet URl: https://x.com/Khamenei_m/status/1854960835757756505\n",
      "Tweet Time: Nov 8\n",
      "Text:  Exclusive\n",
      "\n",
      " “Victory is from God”\n",
      "\n",
      "The short documentary, “Victory is from God,” contains never before seen footages of Martyr Sayyid Hassan Nasrallah's meetings with the Leader of the Islamic Revolution, Imam Khamenei.\n",
      "\n",
      " To watch the full video:\n",
      "https://english.khamenei.ir/news/11235\n",
      "Replies: 398\n",
      "Retweets: 464\n",
      "Likes: 1.8K\n",
      "Views: 67K\n",
      "---\n",
      "Tweet 3:\n",
      "Tweet ID: 1854661917471584285\n",
      "Tweet URl: https://x.com/Khamenei_m/status/1854661917471584285\n",
      "Tweet Time: Nov 8\n",
      "Text:  Coming soon...\n",
      "\n",
      " “Victory is from God”\n",
      "\n",
      "http://Khamenei.ir will soon publish the short documentary, “Victory is from God,” containing never before seen footages of Martyr Sayyid Hassan Nasrallah's meetings with the Leader of the Islamic Revolution, Imam Khamenei.\n",
      "Replies: 174\n",
      "Retweets: 540\n",
      "Likes: 2.5K\n",
      "Views: 74K\n",
      "---\n",
      "Tweet 4:\n",
      "Tweet ID: 1854567692927221947\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854567692927221947\n",
      "Tweet Time: Nov 7\n",
      "Text: #Hezbollah is strong, and it is fighting.\n",
      "Replies: 1.1K\n",
      "Retweets: 1.7K\n",
      "Likes: 12K\n",
      "Views: 458K\n",
      "---\n",
      "Tweet 5:\n",
      "Tweet ID: 1854563582576382241\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854563582576382241\n",
      "Tweet Time: Nov 7\n",
      "Text: The US government has blood on its hands. The US is clearly the Zionists' accomplice in the crimes being committed in Gaza & Lebanon.\n",
      "Replies: 790\n",
      "Retweets: 1.5K\n",
      "Likes: 7.6K\n",
      "Views: 256K\n",
      "---\n",
      "Tweet 6:\n",
      "Tweet ID: 1854520589710393685\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854520589710393685\n",
      "Tweet Time: Nov 7\n",
      "Text: Zionist regime’s goal was to uproot Hamas. It has martyred the leaders of Hamas and imagines that Hamas is finished. Nonetheless, Hamas is still fighting. This means that the Zionist regime has been defeated.\n",
      "Replies: 761\n",
      "Retweets: 876\n",
      "Likes: 4K\n",
      "Views: 206K\n",
      "---\n",
      "Tweet 7:\n",
      "Tweet ID: 1854504619465912598\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854504619465912598\n",
      "Tweet Time: Nov 7\n",
      "Text: Hezbollah grew remarkably thanks to Sayyid Nasrallah’s courage, wisdom, patience & trust in God, and turned into an organization that the well-equipped enemy with all kinds of material, verbal, propaganda, & media weaponry, couldn’t and won’t be able to overcome, God willing.\n",
      "Replies: 225\n",
      "Retweets: 685\n",
      "Likes: 3.3K\n",
      "Views: 89K\n",
      "---\n",
      "Tweet 8:\n",
      "Tweet ID: 1854500399656439909\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854500399656439909\n",
      "Tweet Time: Nov 7\n",
      "Text: Dear Sayyid #Nasrallah has now ascended to join the exalted ranks of the martyrs, achieving the very thing he desired. However, he has also left behind a lasting legacy, which is Hezbollah.\n",
      "Replies: 379\n",
      "Retweets: 630\n",
      "Likes: 3.7K\n",
      "Views: 114K\n",
      "---\n",
      "Tweet 9:\n",
      "Tweet ID: 1854488153886687545\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854488153886687545\n",
      "Tweet Time: Nov 7\n",
      "Text: Martyr Nasrallah, Martyr Haniyeh, Martyr Safieddine, Martyr Yahya Sinwar, and Martyr Nilforoushan have brought honor to the Resistance Front and increased its power and ability.\n",
      "Replies: 451\n",
      "Retweets: 1.1K\n",
      "Likes: 7.4K\n",
      "Views: 164K\n",
      "---\n",
      "Tweet 10:\n",
      "Tweet ID: 1854487517128503501\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854487517128503501\n",
      "Tweet Time: Nov 7\n",
      "Text: We honor the memory of Martyr Ismail #Haniyeh, Martyr #Safieddine, Martyr Yahya #Sinwar, Martyr #Nilforoushan, and all the other martyrs of the Resistance.\n",
      "Replies: 180\n",
      "Retweets: 521\n",
      "Likes: 2.7K\n",
      "Views: 74K\n",
      "---\n",
      "Tweet 11:\n",
      "Tweet ID: 1854485313357250689\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854485313357250689\n",
      "Tweet Time: Nov 7\n",
      "Text: These days coincide with the fortieth day after the martyrdom of the great, tireless mujahid of our time, the late Sayyid Hassan #Nasrallah. We honor his memory.\n",
      "Replies: 311\n",
      "Retweets: 688\n",
      "Likes: 4K\n",
      "Views: 132K\n",
      "---\n",
      "Tweet 12:\n",
      "Tweet ID: 1854484102780457352\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854484102780457352\n",
      "Tweet Time: Nov 7\n",
      "Text: These acts of jihad, which are continuing with strength and power in Lebanon, Gaza, and Palestine today, will definitely lead to the victory of the Resistance Front. This is what we understand from the overall events and also from what God has promised.\n",
      "Replies: 244\n",
      "Retweets: 488\n",
      "Likes: 2.1K\n",
      "Views: 62K\n",
      "---\n",
      "Tweet 13:\n",
      "Tweet ID: 1854483440990646330\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1854483440990646330\n",
      "Tweet Time: Nov 7\n",
      "Text: On this Thursday morning, Imam Khamenei met with the members of the Assembly of Experts of the Leadership in the Imam Khomeini Hussainiyah.\n",
      "Replies: 127\n",
      "Retweets: 295\n",
      "Likes: 2.1K\n",
      "Views: 66K\n",
      "---\n",
      "Tweet 14:\n",
      "Tweet ID: 1853036605637878135\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1853036605637878135\n",
      "Tweet Time: Nov 3\n",
      "Text: All martyrs have a high status. But the martyrdom of these Air Defense Force officers who were defending our country in direct confrontation with the Zionist regime – the most malevolent enemy of Islam – is a martyrdom of great significance.\n",
      "Replies: 956\n",
      "Retweets: 1K\n",
      "Likes: 5.7K\n",
      "Views: 313K\n",
      "---\n",
      "Tweet 15:\n",
      "Tweet ID: 1853035179394183302\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1853035179394183302\n",
      "Tweet Time: Nov 3\n",
      "Text: At noon today, Imam Khamenei met with the families of the martyrs of the Islamic Republic of Iran Air Defense Force who were martyred on Oct. 26, 2024, in the vicious attack by the Zionist regime.\n",
      "Replies: 398\n",
      "Retweets: 633\n",
      "Likes: 4.3K\n",
      "Views: 138K\n",
      "---\n",
      "Tweet 16:\n",
      "Tweet ID: 1852769350614216957\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1852769350614216957\n",
      "Tweet Time: Nov 2\n",
      "Text: Today, the #Americanhumanrights that is touted in various forms no longer deceives anyone.\n",
      "Replies: 473\n",
      "Retweets: 1K\n",
      "Likes: 5.2K\n",
      "Views: 222K\n",
      "---\n",
      "Tweet 17:\n",
      "Tweet ID: 1852765799301173307\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1852765799301173307\n",
      "Tweet Time: Nov 2\n",
      "Text: Those who claim to be advocates of human rights label distinguished figures like Sayyid Hasan #Nasrallah, #Haniyeh, #Soleimani & other great martyrs as terrorists, but they themselves are terrorists & criminal gangs.\n",
      "Replies: 601\n",
      "Retweets: 1.3K\n",
      "Likes: 5.8K\n",
      "Views: 201K\n",
      "---\n",
      "Tweet 18:\n",
      "Tweet ID: 1852759648081698930\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1852759648081698930\n",
      "Tweet Time: Nov 2\n",
      "Text: Ongoing events in #Lebanon & #Gaza have resulted in the martyrdom of 50,000 ppl in the last year, mostly women & children. Is this a small matter? The US that claims to be an advocate of human rights, supports & is complicit in those crimes. Plans & weapons used are from the US.\n",
      "Replies: 636\n",
      "Retweets: 1.8K\n",
      "Likes: 6.7K\n",
      "Views: 197K\n",
      "---\n",
      "Tweet 19:\n",
      "Tweet ID: 1852754341297635784\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1852754341297635784\n",
      "Tweet Time: Nov 2\n",
      "Text: Some sow doubts about whether it’s possible to confront a modern, advanced, dominating, powerful system like the US govt. Yes, the Iranian ppl have fought it & have certainly succeeded so far. Today, the Iranian nation has been able to push back & weaken this great enemy, the US.\n",
      "Replies: 1K\n",
      "Retweets: 1.4K\n",
      "Likes: 7.3K\n",
      "Views: 345K\n",
      "---\n",
      "Tweet 20:\n",
      "Tweet ID: 1852729755730120915\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1852729755730120915\n",
      "Tweet Time: Nov 2\n",
      "Text: For the Iranian ppl who are inspired by teachings of Islam, fighting Arrogance is a duty. Arrogance refers to comprehensive economic, military & cultural domination & humiliation of nations. So, the Iranian ppl’s battle has & will definitely continue to be against Arrogance.\n",
      "Replies: 433\n",
      "Retweets: 908\n",
      "Likes: 4.5K\n",
      "Views: 147K\n",
      "---\n",
      "Tweet 21:\n",
      "Tweet ID: 1852729402750070866\n",
      "Tweet URl: https://x.com/khamenei_ir/status/1852729402750070866\n",
      "Tweet Time: Nov 2\n",
      "Text: Today, the Zionist regime is committing the most atrocious crimes in West Asia. Instead of supporting the people of #Palestine & #Lebanon, some countries are providing economic & military aid to the malicious, cruel, bloodthirsty enemy.\n",
      "Replies: 270\n",
      "Retweets: 1K\n",
      "Likes: 4.3K\n",
      "Views: 109K\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "scrape_twitter_tweets('khamenei_ir', tweet_count=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5feeed78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scroll attempt: 0, Found tweets: 3\n",
      "Scroll attempt: 1, Found tweets: 5\n",
      "Scroll attempt: 2, Found tweets: 7\n",
      "Scroll attempt: 3, Found tweets: 8\n",
      "Scroll attempt: 4, Found tweets: 8\n",
      "Scroll attempt: 5, Found tweets: 8\n",
      "Scroll attempt: 6, Found tweets: 9\n",
      "Scroll attempt: 7, Found tweets: 8\n",
      "Scroll attempt: 8, Found tweets: 8\n",
      "Scroll attempt: 9, Found tweets: 6\n",
      "Tweet 1:\n",
      "Tweet ID: 1856028851421258010\n",
      "Tweet URl: https://x.com/Trump/status/1856028851421258010\n",
      "Tweet Time: Nov 11\n",
      "Text: Happy Veterans Day to the brave men and women who have proudly worn our Nation’s uniform. We are eternally grateful for your sacrifice and unwavering dedication to duty to protect our freedoms. Thank you for all you have given us! #VeteransDay\n",
      "Replies: 28\n",
      "Retweets: 69\n",
      "Likes: 381\n",
      "Views: 11K\n",
      "---\n",
      "Tweet 2:\n",
      "Tweet ID: 1854536378412884006\n",
      "Tweet URl: https://x.com/Trump/status/1854536378412884006\n",
      "Tweet Time: Nov 7\n",
      "Text: Eight years ago, our founder ignited a movement that resonated across America. After decades of passion and energy poured into building and restoring the world’s most iconic properties, he carried that same drive into reshaping our country, committed to making America great\n",
      "Replies: 46\n",
      "Retweets: 126\n",
      "Likes: 564\n",
      "Views: 23K\n",
      "---\n",
      "Tweet 3:\n",
      "Tweet ID: 1853572810096214315\n",
      "Tweet URl: https://x.com/Trump/status/1853572810096214315\n",
      "Tweet Time: Nov 5\n",
      "Text: \"I like thinking big. If you're going to be thinking anything, you might as well think big.\"- Donald J. Trump.\n",
      "\n",
      "At The \n",
      "@Trump\n",
      " Organization, this quote isn’t just a saying—it’s our blueprint. Over 40 years ago, \n",
      "@realdonaldtrump\n",
      "’s bold vision set new standards of excellence. The\n",
      "Replies: 52\n",
      "Retweets: 74\n",
      "Likes: 321\n",
      "Views: 29K\n",
      "---\n",
      "Tweet 4:\n",
      "Tweet ID: 1852055938678579224\n",
      "Tweet URl: https://x.com/Trump/status/1852055938678579224\n",
      "Tweet Time: Oct 31\n",
      "Text: Wishing everyone a Happy Halloween from the historic Macleod House at \n",
      "@TrumpScotland\n",
      " !\n",
      "Replies: 19\n",
      "Retweets: 42\n",
      "Likes: 282\n",
      "Views: 23K\n",
      "---\n",
      "Tweet 5:\n",
      "Tweet ID: 1848165810289729756\n",
      "Tweet URl: https://x.com/Trump/status/1848165810289729756\n",
      "Tweet Time: Oct 21\n",
      "Text: The Fall Collection at \n",
      "@TrumpStore\n",
      " is here!  From soft sweaters to cozy slippers, candles, and more, bring the essence of fall to your home. Shop now: https://bit.ly/4hmfgmS #TrumpStore #FallCollection\n",
      "Replies: 41\n",
      "Retweets: 24\n",
      "Likes: 128\n",
      "Views: 20K\n",
      "---\n",
      "Tweet 6:\n",
      "Tweet ID: 1846620639991562287\n",
      "Tweet URl: https://x.com/Trump/status/1846620639991562287\n",
      "Tweet Time: Oct 16\n",
      "Text: Today, we celebrate the visionary behind it all, \n",
      "@EricTrump\n",
      "! Your dedication to shaping world-class experiences across every Trump property continues to elevate our brand to new heights and sets a standard of excellence that is truly unmatched. From five-star hotels and\n",
      "Replies: 73\n",
      "Retweets: 73\n",
      "Likes: 578\n",
      "Views: 24K\n",
      "---\n",
      "Tweet 7:\n",
      "Tweet ID: 1843719863224902060\n",
      "Tweet URl: https://x.com/Trump/status/1843719863224902060\n",
      "Tweet Time: Oct 8\n",
      "Text: We are thrilled to announce the newest addition to our prestigious portfolio of world-class hotels, championship golf courses, and luxury residences: Trump International Vietnam! Stay tuned for more updates on this exciting project!\n",
      "\n",
      "#TrumpVietnam #Trump #TrumpGolf #TrumpHotels\n",
      "Replies: 29\n",
      "Retweets: 18\n",
      "Likes: 88\n",
      "Views: 19K\n",
      "---\n",
      "Tweet 8:\n",
      "Tweet ID: 1841538704684281906\n",
      "Tweet URl: https://x.com/Trump/status/1841538704684281906\n",
      "Tweet Time: Oct 2\n",
      "Text: We are honored to celebrate our \n",
      "@trumphotels\n",
      " properties for being recognized in the 2024 Conde Nast Traveler Readers’ Choice Awards! \n",
      "@TrumpLasVegas\n",
      " - No. 4 in Las Vegas\n",
      "@TrumpDoonbeg\n",
      " - No. 5 in Europe\n",
      "@TrumpNewYork\n",
      " - No. 8 in New York City\n",
      "@TrumpDoral\n",
      " - No. 8 in Florida\n",
      "Replies: 26\n",
      "Retweets: 15\n",
      "Likes: 72\n",
      "Views: 11K\n",
      "---\n",
      "Tweet 9:\n",
      "Tweet ID: 1838980252715934068\n",
      "Tweet URl: https://x.com/Trump/status/1838980252715934068\n",
      "Tweet Time: Sep 25\n",
      "Text: The Official Trump Coins First Edition President Trump Silver Medallion, Available Now! \n",
      "@realtrumpcoins1\n",
      " \n",
      "\n",
      "http://realtrumpcoins.com #TrumpCoins\n",
      "Replies: 33\n",
      "Retweets: 21\n",
      "Likes: 74\n",
      "Views: 12K\n",
      "---\n",
      "Tweet 10:\n",
      "Tweet ID: 1835036395393688036\n",
      "Tweet URl: https://x.com/Trump/status/1835036395393688036\n",
      "Tweet Time: Sep 14\n",
      "Text: We love pets at \n",
      "@TrumpHotels\n",
      "!  With #TrumpPets, your furry friends get the VIP treatment—gourmet treats, plush beds, and more. Learn more: https://bit.ly/47sxfmY #Trump #TrumpHotels\n",
      "Replies: 125\n",
      "Retweets: 447\n",
      "Likes: 1.3K\n",
      "Views: 314K\n",
      "---\n",
      "Tweet 11:\n",
      "Tweet ID: 1833863682230481096\n",
      "Tweet URl: https://x.com/Trump/status/1833863682230481096\n",
      "Tweet Time: Sep 11\n",
      "Text: Today, we pause to honor the memory of 9/11, a day that forever changed our nation and the world. We unite to remember the lives lost and the heroes who selflessly gave theirs in service. Your sacrifice will never be forgotten. Together, we stand in remembrance, and we will\n",
      "Replies: 33\n",
      "Retweets: 56\n",
      "Likes: 277\n",
      "Views: 15K\n",
      "---\n",
      "Tweet 12:\n",
      "Tweet ID: 1832213287519580577\n",
      "Tweet URl: https://x.com/Trump/status/1832213287519580577\n",
      "Tweet Time: Sep 7\n",
      "Text: We are thrilled to unveil the newest addition to \n",
      "@trumpscotland\n",
      ": the ‘Great North Sea Links!’ These new modern links joins our existing 18-hole masterpiece to create the Greatest 36 Holes on Earth! \n",
      "\n",
      "Set against the stunning backdrop of the Aberdeenshire coastline and spanning\n",
      "Replies: 33\n",
      "Retweets: 23\n",
      "Likes: 102\n",
      "Views: 12K\n",
      "---\n",
      "Tweet 13:\n",
      "Tweet ID: 1829532295763800146\n",
      "Tweet URl: https://x.com/Trump/status/1829532295763800146\n",
      "Tweet Time: Aug 30\n",
      "Text: Get ready to celebrate the end of summer with \n",
      "@TrumpStore\n",
      "! Enjoy 20% off select products that proudly feature patriotic accents, apparel, and more to Shop now through Monday!\n",
      "Replies: 25\n",
      "Retweets: 7\n",
      "Likes: 46\n",
      "Views: 10K\n",
      "---\n",
      "Tweet 14:\n",
      "Tweet ID: 1828167583675064493\n",
      "Tweet URl: https://x.com/Trump/status/1828167583675064493\n",
      "Tweet Time: Aug 26\n",
      "Text: Tucked beneath Wall Street, The Vaults at 40 Wall Street reveal a transformed piece of history. With a wine tasting room, lounge, café, and conference rooms, every detail—from original vault doors to Italian marble—celebrates the building’s rich past. Visit the link for an\n",
      "Replies: 24\n",
      "Retweets: 24\n",
      "Likes: 80\n",
      "Views: 11K\n",
      "---\n",
      "Tweet 15:\n",
      "Tweet ID: 1825928225316360534\n",
      "Tweet URl: https://x.com/TrumpGolf/status/1825928225316360534\n",
      "Tweet Time: Aug 20\n",
      "Text: Discover \n",
      "@TrumpCharlotte\n",
      "—the ultimate luxury private golf destination. \n",
      "\n",
      "Challenge yourself on our 18-hole course by Lake Norman, then relax with dining, racquets, aquatics, and spa amenities.\n",
      "\n",
      "Learn more: https://bit.ly/3X7jdnb\n",
      "Replies: 40\n",
      "Retweets: 49\n",
      "Likes: 183\n",
      "Views: 15K\n",
      "---\n",
      "Tweet 16:\n",
      "Tweet ID: 1821269658806165743\n",
      "Tweet URl: https://x.com/Trump/status/1821269658806165743\n",
      "Tweet Time: Aug 7\n",
      "Text: The historic \n",
      "@TrumpTurnberry\n",
      " Lighthouse, built in 1873, has guided ships and captured imaginations. Now, it houses a world-renowned halfway house and a luxurious suite with stunning views of the Irish Sea and Isle of Arran.\n",
      "Replies: 88\n",
      "Retweets: 22\n",
      "Likes: 108\n",
      "Views: 24K\n",
      "---\n",
      "Tweet 17:\n",
      "Tweet ID: 1814096853769576727\n",
      "Tweet URl: https://x.com/Trump/status/1814096853769576727\n",
      "Tweet Time: Jul 19\n",
      "Text: Become Part of the World of Trump: Your exclusive access awaits!\n",
      "\n",
      "With over four decades of setting new standards in world-class hotels, luxury residential real estate, top-tier office buildings, championship golf clubs, e-commerce, and more, The Trump Organization boasts an\n",
      "Replies: 163\n",
      "Retweets: 35\n",
      "Likes: 122\n",
      "Views: 55K\n",
      "---\n",
      "Tweet 18:\n",
      "Tweet ID: 1813922136362217525\n",
      "Tweet URl: https://x.com/Trump/status/1813922136362217525\n",
      "Tweet Time: Jul 18\n",
      "Text: The Ailsa course at \n",
      "@TrumpTurnberry\n",
      ", renowned for both its beauty and immense challenge, has etched unforgettable moments into golf history. As we approach the 152nd Open Championship, we're reminded of its storied legacy and continued impact on the world stage.\n",
      "\n",
      "Recently ranked\n",
      "Replies: 60\n",
      "Retweets: 18\n",
      "Likes: 104\n",
      "Views: 39K\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "scrape_twitter_tweets('trump', tweet_count=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
